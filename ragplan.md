# План внедрения RAG с QdrantDB

Цель: добавить Retrieval-Augmented Generation так, чтобы агент отвечал только на основе загруженных файлов. Источник знаний хранится в Qdrant; ключи и вызовы моделей остаются на сервере.

## 1) Архитектура (в общих чертах)
- Клиент (существующий `index.html`/`script.js`): отправляет запросы на бэкенд, не хранит ключи.
- Сервер (`server.js`):
  - `POST /api/ask` — приём вопроса, поиск по Qdrant, формирование промпта, вызов модели, возврат ответа + цитаты.
  - (Опционально) `POST /api/ingest` — загрузка файлов через HTTP; для локалки проще отдельный скрипт `ingest.js`.
- Хранилище: Qdrant (локально через Docker или Managed Qdrant). Одна коллекция, например `docs`.
- Векторизация: OpenAI `text-embedding-3-small` (1536 dims) или другой провайдер; выбор фиксирует размер векторов коллекции.

## 2) Инфраструктура и окружение
- Переменные окружения:
  - `OPENAI_API_KEY` — ключ LLM/эмбеддингов (сервер).
  - `QDRANT_URL` — например `http://localhost:6333`.
  - `QDRANT_API_KEY` — если используется облако (иначе не нужен).
  - `QDRANT_COLLECTION` — имя коллекции (по умолчанию `docs`).
- Локальный Qdrant (пример):
  - Docker: `docker run -p 6333:6333 qdrant/qdrant:latest`.
  - Панель: `http://localhost:6333/dashboard`.

## 3) Модель данных в Qdrant
- Коллекция `docs` (пример):
  - `vector_size` = 1536 (если используем `text-embedding-3-small`).
  - `distance` = `Cosine`.
  - HNSW + фильтрация по метаданным.
- Точка (point) в Qdrant:
  - `id`: строка вида `docId:chunkIndex`.
  - `vector`: эмбеддинг чанка.
  - `payload` (мета): `{ doc_id, source, title, chunk_index, text, tokens, loc: {start, end}, url?, tags? }`.

## 4) Инжест (подготовка базы знаний)
- Источники: `.md`, `.txt`, `.pdf` (минимальный набор). Для PDF — парсинг в текст (pdf-parse или аналог).
- Очистка текста: удаление служебного мусора, нормализация пробелов.
- Чанкинг:
  - Размер: 800–1200 токенов (или 1500–2500 символов как приближение), перекрытие 150–250.
  - Стратегия: семантические разрывы (по заголовкам/абзацам) + склейка до целевого размера.
- Эмбеддинги: батчами (чтобы не упираться в лимиты API), кэшировать по `sha256(text)`.
- Запись в Qdrant: upsert по батчам (с метаданными). Если коллекции нет — создать.
- Утилита `ingest.js` (CLI):
  - Аргументы: `--dir ./knowledge` (папка с файлами), `--collection docs`, `--overwrite?`.
  - Вывод: кол-во файлов, чанков, ошибок.

## 5) Поиск и ранжирование
- Запрос пользователя → эмбеддинг → векторный поиск topK в Qdrant (например, `k=8`).
- Фильтры: по `tags`, `doc_id` (если нужно ограничить область).
- MMR (Maximum Marginal Relevance) или простая дедупликация по `doc_id` для разнообразия контекста.
- Порог релевантности: отбрасывать чанки ниже `similarity_threshold` (например 0.75 по косинусу; калибровать по данным).
- Итоговый контекст: конкатенация чанков до лимита токенов промпта; сохранять порядок по релевантности.

## 6) Промпт и генерация ответа
- Системное сообщение (строгость):
  - «Отвечай только на основе предоставленного контекста. Если информации недостаточно — скажи, что не знаешь. Добавляй ссылки на источники (doc_id или title и номер чанка).»
- Формат промпта:
  - `Context:` список блоков вида:
    - `[doc_id:chunk_index] <фрагмент текста>`
  - `Question:` пользовательский вопрос
  - `Instructions:` краткость, русский ответ, список цитат.
- Параметры генерации: низкая температура (0.0–0.3), `model = gpt-4o-mini` (или выбранная).
- Защита от галлюцинаций: проверять, что есть хотя бы один чанк выше порога, иначе отвечать «Недостаточно информации в базе знаний.»

## 7) Серверные маршруты
- `POST /api/ask`
  - Вход: `{ query: string, topK?: number, filters?: {...} }`.
  - Шаги: валидировать → эмбеддинг запроса → поиск в Qdrant → сбор контекста → вызов LLM → вернуть `{ answer, citations: [{doc_id, chunk_index, score, source?, url?}] }`.
  - Ошибки: 400 на пустой `query`, 502 при пустом ответе модели, 500 — системные.
- (Опционально) `POST /api/ingest`
  - Для аплоада файлов через HTTP; для простоты первой версии использовать CLI `ingest.js`.

## 8) Изменения во фронтенде
- Обновить `script.js`:
  - Вместо `/api/chat` вызывать `/api/ask` c `{ query }` (или адаптировать текущую структуру сообщений).
  - Показ цитат: под ответом отобразить список источников; клик — открывает файл/якорь (если есть `url`).
  - UX: индикатор «Поиск по базе…», graceful‐fallback на заглушку, если сервер вернул 4xx/5xx.

## 9) Качество и ограничения
- Лимиты токенов: контролировать размер контекста; если переполнение — сокращать по убыванию релевантности.
- Язык/локаль: все подсказки и ответы — на русском.
- Валидация ввода: длина `query`, запрет бинарных/пустых запросов.
- Логи: измерять время стадий (эмбеддинг, поиск, генерация), размер контекста, k.

## 10) Безопасность
- Ключи только на сервере (как сейчас). Никогда не в клиенте.
- CORS: как в `server.js`, whitelist только локальные origin.
- Qdrant API ключ/URL в окружении; не коммитить.
- Санитайзинг входящих файлов при инжесте (имена, пути, размер, тип).

## 11) Тест-план (ручной)
- Наполнить `./knowledge` 2–3 документами на разные темы.
- `node ingest.js --dir ./knowledge` → убедиться, что в Qdrant появились точки.
- Вопрос «внутри домена» → получить осмысленный ответ + 2–4 цитаты.
- Вопрос «вне домена» → получить «Не знаю/Недостаточно информации». Галлюцинаций быть не должно.
- Проверить производительность: холодный старт (пустой кэш) и тёплый.

## 12) Дорожная карта
- V1: CLI-инжест, `POST /api/ask`, базовый поиск (topK, threshold), базовые цитаты.
- V2: MMR/реранкинг, улучшенный чанкинг, предпросмотр источников во фронте.
- V3: Инжест через UI, операции обновления/удаления документов, версии коллекций.
- V4: Telemetry/metrics, тесты на качество (simple QA set), бенчмарки.

## 13) Эскизы реализаций (псевдокод)
- `ingest.js` (CLI):
  1. Пройтись по файлам `--dir` → распарсить в текст.
  2. Разбить на чанки (size, overlap) + метаданные.
  3. Получить эмбеддинги батчами.
  4. Создать коллекцию в Qdrant (если нет) с нужным `vector_size`.
  5. Upsert points (vector + payload). Логировать прогресс.
- `/api/ask`:
  1. Валидировать `query`.
  2. Эмбеддинг запроса.
  3. Поиск `topK` в Qdrant (+фильтры, порог, MMR).
  4. Сформировать контекст (до лимита токенов).
  5. Вызвать чат-комплишн (низкая температура) с инструкцией «отвечать только по контексту».
  6. Вернуть ответ + цитаты (источники из payload наиболее релевантных чанков).

---

Примечание: первая версия рекомендует оставлять инжест вне HTTP (CLI‐скрипт), чтобы ускорить разработку и упростить валидацию/логгирование. Позже можно добавить `POST /api/ingest` и UI‐аплоад.

